# ğŸ”ï¸ Snowflake Data Quality & Documentation Platform

<div align="center">

**A comprehensive Streamlit application for enhancing data governance in Snowflake through AI-powered documentation, automated data quality monitoring, and contact management.**

[![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)](https://streamlit.io/)
[![Snowflake](https://img.shields.io/badge/Snowflake-29B5E8?style=for-the-badge&logo=snowflake&logoColor=white)](https://snowflake.com/)
[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org/)

*Optimized for **Streamlit in Snowflake (SiS)** with full local development support*

</div>

---

## ğŸ“º Demo & Overview

[<img src="https://img.youtube.com/vi/OdKl4yq7ikY/maxresdefault.jpg" width="60%">](https://youtu.be/OdKl4yq7ikY)

*Click to watch the full demo and feature walkthrough*

---

## ğŸ“‹ Table of Contents

- [ğŸ¯ Purpose & Value Proposition](#-purpose--value-proposition)
- [ğŸ—ï¸ Architecture & Project Structure](#ï¸-architecture--project-structure)
- [ğŸ”„ Application Flow](#-application-flow)
- [ğŸŒŸ Core Features](#-core-features)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ” Required Permissions](#-required-permissions)
- [ğŸ“– User Guide](#-user-guide)
- [ğŸ”— Documentation & Resources](#-documentation--resources)
- [ğŸ”§ Technical Architecture](#-technical-architecture)
- [ğŸš¨ Troubleshooting](#-troubleshooting)
- [ğŸ“Š Best Practices](#-best-practices)
- [ğŸ”„ Version History](#-version-history)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“ Support & Resources](#-support--resources)

---

## ğŸ¯ Purpose & Value Proposition

This application transforms your Snowflake environment into a **well-documented, high-quality data platform** by providing:

- **ğŸ¤– AI-Powered Documentation**: Leverage Snowflake Cortex LLMs to automatically generate intelligent table and column descriptions
- **ğŸ” Data Quality Monitoring**: Comprehensive Data Metric Functions (DMF) setup and monitoring dashboard
- **ğŸ‘¥ Data Governance**: Complete contact management system for data stewards, technical support, and access approvers
- **ğŸ“Š Executive Insights**: Real-time KPIs and governance metrics for data leadership
- **ğŸ“ˆ Audit & Compliance**: Complete historical tracking of all changes and improvements
- **ğŸ—ï¸ Enterprise-Ready**: Native Snowflake integration with no external dependencies

### ğŸ¯ Target Audience

- **Data Engineers**: Streamline data quality monitoring and documentation workflows
- **Data Stewards**: Maintain comprehensive data governance and contact management
- **Analytics Teams**: Ensure high-quality, well-documented data for analysis
- **Data Leaders**: Monitor governance KPIs and compliance metrics
- **Platform Teams**: Deploy enterprise-grade data governance tools

---

## ğŸ—ï¸ Architecture & Project Structure

### ğŸ“ Modular Architecture

This application follows a **clean, modular architecture** that was refactored from a monolithic 4,000+ line file into maintainable, scalable components:

```
db-snowdq/
â”œâ”€â”€ ğŸš€ app.py                          # Main application entry point (232 lines)
â”œâ”€â”€ ğŸ“„ README.md                       # This comprehensive documentation
â”œâ”€â”€ ğŸ”§ environment.yml                 # SiS-compatible dependencies
â”‚
â”œâ”€â”€ ğŸ“± components/                     # Reusable UI Components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ styles.py                      # CSS styling & theme management (285 lines)
â”‚
â”œâ”€â”€ ğŸ“„ pages/                          # Individual Page Modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ğŸ  home.py                     # Executive dashboard & KPIs
â”‚   â”œâ”€â”€ ğŸ“ data_descriptions.py        # AI-powered description generation
â”‚   â”œâ”€â”€ ğŸ” data_quality.py            # Data Metric Functions (DMF) configuration
â”‚   â”œâ”€â”€ ğŸ‘¥ data_contacts.py           # Data governance contact management
â”‚   â””â”€â”€ ğŸ“ˆ history.py                 # Historical tracking & audit trails
â”‚
â”œâ”€â”€ ğŸ› ï¸ utils/                          # Utility Modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ğŸ—„ï¸ database.py                # Snowflake connections & SQL utilities
â”‚   â”œâ”€â”€ ğŸ“Š data_fetchers.py           # Cached data retrieval functions
â”‚   â”œâ”€â”€ ğŸ¤– ai_utils.py                # Snowflake Cortex LLM integration
â”‚   â”œâ”€â”€ âš™ï¸ setup.py                   # Database setup & session management
â”‚   â”œâ”€â”€ ğŸ“ˆ kpi_utils.py               # KPI calculations & metrics
â”‚   â”œâ”€â”€ ğŸ“ description_helpers.py     # Description generation workflows
â”‚   â””â”€â”€ ğŸ” dmf_utils.py               # Data Metric Functions utilities
â”‚
â””â”€â”€ ğŸ“œ sql/                           # Database Setup Scripts
    â”œâ”€â”€ setup_db_snowtools.sql        # Core database objects
    â””â”€â”€ setup_app_permissions.sql     # Required permissions
```

### ğŸ”„ Migration Benefits

| **Before (Monolithic)** | **After (Modular)** |
|--------------------------|----------------------|
| âŒ Single 4,000+ line file | âœ… Clean separation of concerns |
| âŒ Difficult to maintain | âœ… Easy to maintain and extend |
| âŒ Hard to test components | âœ… Testable individual modules |
| âŒ Poor code organization | âœ… Professional structure |
| âŒ Single developer bottleneck | âœ… Multiple developers can contribute |

---

## ğŸ”„ Application Flow

The following diagram illustrates how the different components of the application work together:

```mermaid
graph TD
    A["ğŸ  Home Dashboard<br/>KPIs & Overview"] --> B["ğŸ“ Data Descriptions<br/>AI-Powered Documentation"]
    A --> C["ğŸ” Data Quality<br/>DMF Configuration"]
    A --> D["ğŸ‘¥ Data Contacts<br/>Governance Management"]
    A --> E["ğŸ“ˆ History<br/>Audit & Tracking"]
    
    B --> F["ğŸ¤– Snowflake Cortex<br/>LLM Models"]
    B --> G["ğŸ“Š INFORMATION_SCHEMA<br/>Metadata Queries"]
    
    C --> H["ğŸ” Data Metric Functions<br/>Quality Monitoring"]
    C --> I["ğŸ“Š Quality Dashboard<br/>Results & Trends"]
    
    D --> J["ğŸ‘¤ Contact Assignment<br/>Stewards & Approvers"]
    D --> K["ğŸ”— Snowflake Contacts<br/>Native Integration"]
    
    E --> L["ğŸ“ Description History<br/>Change Tracking"]
    E --> M["ğŸ” DMF History<br/>Quality Config Audit"]
    E --> N["ğŸ“¤ CSV Export<br/>Compliance Reports"]
    
    F --> O["ğŸ’¾ DB_SNOWTOOLS<br/>History Storage"]
    G --> O
    H --> O
    J --> O
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#fce4ec
    style F fill:#e0f2f1
    style O fill:#fff8e1
```

---

## ğŸŒŸ Core Features

### ğŸ¤– AI-Powered Data Documentation

Transform your undocumented tables and columns into comprehensive, intelligent documentation:

- **ğŸ§  Multi-Model Support**: Choose from Snowflake Cortex models:
  - `claude-4-sonnet` (Premium reasoning)
  - `mistral-large2` (Balanced performance)
  - `llama3-70b` (Open source)
  - `snowflake-arctic` (Snowflake optimized)
  - `snowflake-llama-3.1-405b` (Latest large model)

- **ğŸ¯ Smart Context Analysis**: Analyzes table structure, column types, and sample data
- **âš¡ Bulk Operations**: Generate descriptions for multiple tables and columns simultaneously
- **ğŸ” View Support**: Advanced DDL parsing and recreation for complex views
- **ğŸ“ Optimized Output**: 150 chars for tables, 100 chars for columns
- **ğŸ‘€ Real-time Preview**: Review generated descriptions before applying

### ğŸ” Advanced Data Quality Monitoring

Comprehensive Data Metric Functions (DMF) setup and monitoring:

#### ğŸ“Š Supported Metrics

| **Level** | **Metric Types** | **Use Cases** |
|-----------|------------------|---------------|
| **Table** | `ROW_COUNT`, `FRESHNESS` | Monitor data volume and recency |
| **Column** | `NULL_COUNT`, `NULL_PERCENT` | Data completeness validation |
| **Column** | `DUPLICATE_COUNT`, `UNIQUE_COUNT` | Data uniqueness monitoring |
| **Column** | `ACCEPTED_VALUES` | Domain validation |
| **Column** | `AVG`, `MAX`, `MIN`, `STDDEV` | Statistical monitoring |

#### âš™ï¸ Configuration Features

- **ğŸ• Flexible Scheduling**: Periodic (minutes/hours), daily, or trigger-on-changes
- **ğŸ›ï¸ Bulk Configuration**: Apply metrics to all columns or configure individually
- **ğŸ“œ SQL Generation**: Download ready-to-execute SQL scripts
- **ğŸ“Š Results Dashboard**: Comprehensive monitoring with filters and KPIs
- **ğŸ“ˆ Historical Analysis**: Track quality trends over time

### ğŸ‘¥ Data Governance & Contacts

Complete contact management system for data governance:

- **ğŸ‘¤ Contact Types**:
  - **Data Steward**: Primary data owner and quality manager
  - **Technical Support**: Technical issues and system access
  - **Access Approver**: Data access request approvals

- **ğŸ” Current Assignments**: View existing contacts for any table
- **ğŸ“ Pre-populated Forms**: Automatically populate dropdowns with existing assignments
- **ğŸ“œ SQL Generation**: Generate `ALTER TABLE SET CONTACT` statements
- **ğŸ”— Native Integration**: Seamless integration with Snowflake's contact system

### ğŸ“Š Executive Dashboard & KPIs

Real-time governance metrics for data leadership:

- **ğŸ“ˆ Real-time Metrics**:
  - Total Databases, Schemas, Tables & Views
  - Documentation coverage percentage
  - Active data quality monitors
  - Contact assignments coverage

- **ğŸ¨ Visual KPI Cards**: Modern, gradient-styled metric displays
- **ğŸ”„ Manual Refresh**: Force refresh of all KPIs from Snowflake
- **ğŸ“Š Trend Analysis**: Monitor improvements over time

### ğŸ“ˆ Comprehensive History & Audit

Complete audit trail for compliance and governance:

- **ğŸ“ Description History**: Track all table, view, and column description changes
- **ğŸ” DMF Configuration History**: Monitor data quality setup changes
- **ğŸ‘¥ Contact Assignment History**: Audit trail for governance assignments
- **ğŸ“¤ Export Capabilities**: Download history as CSV for compliance reporting
- **ğŸ‘¤ User Attribution**: Track who made what changes when

---

## ğŸš€ Quick Start

### ğŸ”ï¸ Option 1: Streamlit in Snowflake (Recommended)

1. **ğŸ“¤ Upload Files**: Upload `app.py`, `pages/`, `components/`, `utils/` directories, and `environment.yml` to your Snowflake stage
2. **ğŸ¯ Create App**: Create the Streamlit app in Snowflake
3. **â–¶ï¸ Run**: Launch the app - it will auto-setup required database objects
4. **ğŸ” Grant Permissions**: Configure permissions as needed (see permissions section)

### ğŸ’» Option 2: Local Development

```bash
# Clone the repository
git clone <repository-url>
cd db-snowdq

# Install dependencies
pip install -r requirements.txt

# Configure Snowflake connection
# Create ~/.snowflake/connections.toml with your credentials

# Run the application
streamlit run app.py
```

### âš™ï¸ Automatic Setup

The app automatically creates required database objects on first run:
- âœ… `DB_SNOWTOOLS` database
- âœ… `DATA_DESCRIPTION_HISTORY` table
- âœ… `DATA_QUALITY_RESULTS` table

---

## ğŸ” Required Permissions

### ğŸ”ï¸ Core System Access

```sql
-- Metadata and system access
GRANT IMPORTED PRIVILEGES ON DATABASE SNOWFLAKE TO ROLE your_role;
GRANT DATABASE ROLE SNOWFLAKE.OBJECT_VIEWER TO ROLE your_role;

-- Cortex LLM access for AI descriptions
GRANT DATABASE ROLE SNOWFLAKE.CORTEX_USER TO ROLE your_role;

-- Data quality monitoring
GRANT DATABASE ROLE SNOWFLAKE.DATA_METRIC_USER TO ROLE your_role;
GRANT APPLICATION ROLE SNOWFLAKE.DATA_QUALITY_MONITORING_LOOKUP TO ROLE your_role;
```

### ğŸ“Š Data Access (Customize for Your Databases)

```sql
-- Grant access to your data databases
GRANT USAGE ON DATABASE your_database TO ROLE your_role;
GRANT USAGE ON ALL SCHEMAS IN DATABASE your_database TO ROLE your_role;
GRANT SELECT ON ALL TABLES IN DATABASE your_database TO ROLE your_role;
GRANT SELECT ON ALL VIEWS IN DATABASE your_database TO ROLE your_role;

-- For description updates
GRANT MODIFY ON ALL TABLES IN DATABASE your_database TO ROLE your_role;
GRANT MODIFY ON ALL VIEWS IN DATABASE your_database TO ROLE your_role;

-- For contact management
GRANT REFERENCES ON ALL TABLES IN DATABASE your_database TO ROLE your_role;
```

### ğŸ” DMF Setup (For Data Quality)

```sql
-- For setting up Data Metric Functions
GRANT OWNERSHIP ON TABLE your_database.your_schema.your_table TO ROLE your_role;
-- OR
GRANT ALL PRIVILEGES ON TABLE your_database.your_schema.your_table TO ROLE your_role;
```

---

## ğŸ“– User Guide

### ğŸ  Home Dashboard
- **ğŸ“Š KPI Overview**: View real-time governance metrics
- **ğŸš€ Quick Actions**: Navigate directly to key features
- **â„¹ï¸ System Information**: Connection details and platform overview
- **âœ… Setup Status**: Verify database objects are configured

### ğŸ“ Data Descriptions
1. **ğŸ¯ Select Database/Schema**: Choose your target objects
2. **ğŸ” Filter Objects**: Show only undocumented items
3. **ğŸ¤– Choose LLM Model**: Select from available Cortex models
4. **â˜‘ï¸ Select Objects**: Use checkboxes to choose tables/views
5. **âš¡ Generate Descriptions**: Choose table, column, or both
6. **ğŸ‘€ Review Results**: View generated descriptions in collapsible sections
7. **ğŸ”„ Refresh Data**: Use the refresh button to see applied changes

### ğŸ” Data Quality
1. **ğŸ¯ Select Target Table**: Choose database, schema, and table
2. **â° Set Schedule**: Configure monitoring frequency
3. **ğŸ“Š Choose DMFs**: Select table-level and column-level metrics
4. **ğŸ“œ Generate SQL**: Download or apply DMF configuration
5. **ğŸ“ˆ Monitor Results**: View quality check results and trends

### ğŸ‘¥ Data Contacts
1. **ğŸ¯ Select Table**: Choose your target table
2. **ğŸ‘€ View Current Contacts**: See existing assignments
3. **âœï¸ Update Assignments**: Set steward, support, and approver contacts
4. **âœ… Apply Changes**: Execute generated SQL or download for later

### ğŸ“ˆ History
- **ğŸ“ Description History**: Track all documentation changes
- **ğŸ” Quality History**: Comprehensive DMF monitoring dashboard
- **ğŸ“¤ Export Options**: Download history data for reporting

---

## ğŸ”— Documentation & Resources

### ğŸ“š Official Snowflake Documentation

- **ğŸ” Data Metric Functions (DMF)**: [Snowflake DMF Documentation](https://docs.snowflake.com/en/user-guide/data-quality-intro)
- **ğŸ¤– Snowflake Cortex**: [Cortex LLM Functions](https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions)
- **ğŸ‘¥ Data Governance**: [Contact Management](https://docs.snowflake.com/en/sql-reference/sql/alter-table#contact-management)
- **ğŸ”ï¸ Streamlit in Snowflake**: [SiS Documentation](https://docs.snowflake.com/en/developer-guide/streamlit/about-streamlit)
- **ğŸ” Access Control**: [RBAC Guide](https://docs.snowflake.com/en/user-guide/security-access-control-overview)

### ğŸ› ï¸ Technical References

- **ğŸ“Š INFORMATION_SCHEMA**: [Metadata Views](https://docs.snowflake.com/en/sql-reference/info-schema)
- **ğŸ” Data Quality Monitoring**: [Quality Results](https://docs.snowflake.com/en/user-guide/data-quality-monitoring)
- **ğŸ¯ Best Practices**: [Data Governance](https://docs.snowflake.com/en/user-guide/data-governance-overview)

---

## ğŸ”§ Technical Architecture

### ğŸ”ï¸ SiS Compatibility Features

- **ğŸ” Primary Queries**: Uses `INFORMATION_SCHEMA` views for consistent results
- **ğŸ”„ Fallback System**: Automatic fallback to `SHOW` commands when needed
- **ğŸ” Permission Handling**: Graceful degradation with helpful error messages
- **ğŸ› Debug Mode**: Detailed logging for troubleshooting permission issues

### âš¡ Performance Optimizations

- **ğŸ’¾ Intelligent Caching**: `@st.cache_data` with TTL for optimal performance
- **ğŸ“¦ Batch Operations**: Efficient bulk processing for large datasets
- **ğŸ­ Minimal Warehouse Usage**: Optimized for small warehouse compatibility
- **ğŸ§  Memory Management**: Designed for SiS 32MB data transfer limits

### ğŸ”’ Security & Compliance

- **ğŸ” Role-Based Access Control**: Follows Snowflake RBAC best practices
- **ğŸ“‹ Complete Audit Trail**: All changes tracked with user attribution
- **ğŸ”’ Data Privacy**: No external data transfers (runs entirely in Snowflake)
- **ğŸ›¡ï¸ Permission Isolation**: Clear separation between app and user data access

---

## ğŸš¨ Troubleshooting

### ğŸ”ï¸ Common SiS Issues

**Tables/Columns Not Displaying**
- âœ… **Fixed**: Now uses `INFORMATION_SCHEMA` queries for better compatibility
- Check app owner has proper database access permissions
- Verify `INFORMATION_SCHEMA` access is available

**Permission Errors**
- Ensure app owner role has required system privileges
- Grant `USAGE` on target databases and schemas
- Verify Cortex and DMF roles are properly assigned

**DMF Setup Failures**
- DMFs require table ownership or full privileges
- Run generated SQL with appropriate role
- Check that schedules are properly configured

### âš¡ Performance Issues

- Use smaller warehouse for better cost efficiency
- Enable caching by avoiding frequent page refreshes
- Filter to specific databases/schemas for large environments

### ğŸ¤– Model Availability

- Check available models: `SELECT * FROM SNOWFLAKE.CORTEX.COMPLETE_AVAILABLE_MODELS()`
- Verify account region supports selected models
- Try different models if one is unavailable

---

## ğŸ“Š Best Practices

### ğŸ‘¥ For Data Stewards

1. **ğŸ¯ Prioritize High-Value Tables**: Start with frequently-used, business-critical tables
2. **ğŸ“ Maintain Consistency**: Use consistent description styles across your organization
3. **ğŸ‘€ Review AI Output**: Always review and refine AI-generated descriptions
4. **ğŸ” Monitor Quality**: Set up data quality monitoring on critical tables
5. **ğŸ‘¤ Assign Ownership**: Ensure clear contact assignments for all important tables

### ğŸ”§ For Administrators

1. **ğŸ” Minimal Permissions**: Grant minimal required permissions initially
2. **ğŸ’° Monitor Costs**: Track Cortex usage for cost management
3. **â° Smart Scheduling**: Set appropriate DMF schedules (avoid over-monitoring)
4. **ğŸ“‹ Compliance**: Use history tracking for compliance reporting
5. **ğŸ’¾ Backup Strategy**: Regular backup of `DB_SNOWTOOLS` database

### ğŸ‘¨â€ğŸ’» For Developers

1. **ğŸ§ª Test Environments**: Test in both SiS and local environments
2. **ğŸ› Use Debug Info**: Leverage debug information for troubleshooting
3. **ğŸ”„ Error Patterns**: Follow established error handling patterns
4. **â¬†ï¸ Backward Compatibility**: Maintain compatibility when extending features

---

## ğŸ”„ Version History

### ğŸ‰ v2.0 - Modular Architecture & Enhanced Features
- âœ… **Modular Refactor**: Clean separation from 4,000+ line monolith
- âœ… **SiS Optimization**: Full compatibility with Streamlit in Snowflake
- âœ… **INFORMATION_SCHEMA**: Primary queries for better permission handling
- âœ… **Enhanced UI**: Modern KPI dashboard and improved navigation
- âœ… **Complete DMF**: Comprehensive data quality monitoring dashboard
- âœ… **Contact Management**: Full data governance contact system
- âœ… **History Tracking**: Complete audit trail for all operations
- âœ… **Error Handling**: Graceful degradation with helpful messages

### ğŸš€ v1.0 - Core Features
- AI-powered description generation
- Basic DMF setup
- Multi-page navigation
- Local development support

---

## ğŸ¤ Contributing

This application follows Snowflake best practices and is designed for easy extension:

### ğŸ”§ Development Setup

```bash
# Clone and setup
git clone <repository-url>
cd db-snowdq
pip install -r requirements.txt

# Run locally
streamlit run app.py
```

### ğŸ“ Adding New Features

- **ğŸ¤– Add LLM Models**: Update `AVAILABLE_MODELS` list in `utils/ai_utils.py`
- **ğŸ” Extend DMF Support**: Add new metric types in `utils/dmf_utils.py`
- **ğŸ“„ New Pages**: Follow the pattern in `pages/` directory
- **ğŸ¨ UI Improvements**: Maintain the modern, gradient-styled design system

### ğŸ§ª Testing Guidelines

1. Test in both SiS and local environments
2. Verify all imports and dependencies
3. Check error handling and edge cases
4. Maintain backward compatibility

---

## ğŸ“ Support & Resources

- **ğŸ“– In-App Documentation**: Check the Documentation tab within the app
- **ğŸ“œ Setup Scripts**: Review `sql/setup_*.sql` files for manual setup
- **ğŸ› Troubleshooting**: Use the debug information provided by the app
- **ğŸ” Permissions**: Verify against the detailed permissions section above

---

<div align="center">

**ğŸ¯ Built for Modern Data Teams**

*Transform your Snowflake environment into a well-documented, high-quality data platform with AI-powered automation and comprehensive governance tools!*

**ğŸ”º Snowflake Native** â€¢ **ğŸ”’ Enterprise Secure** â€¢ **âš¡ High Performance**

*Runs entirely within your Snowflake environment with no external dependencies or data transfers.*

---

**â­ Star this repository if it helps your data governance journey!**

</div>